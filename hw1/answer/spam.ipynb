{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed5519d1",
   "metadata": {},
   "source": [
    "Ex4(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b8f0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  ['training_data', 'training_labels', 'test_data']\n",
      "training_data shape: (4171, 32)\n",
      "training_labels shape: (4171,)\n",
      "test_data shape: (1000, 32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load('../data/spam-data.npz')\n",
    "print(\"data: \", data.files)\n",
    "for name in data.files:\n",
    "    arr = data[name]\n",
    "    print(f\"{name} shape: {arr.shape}\")\n",
    "    # print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1923b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split MNIST data into training and validation sets\n",
    "\n",
    "def split_mnist_data(X, y, num_val=10000, random_seed=42):\n",
    "    \"\"\"\n",
    "    Shuffle and split MNIST data into training and validation sets.\n",
    "    Args:\n",
    "        X: numpy array of images, shape (N, D)\n",
    "        y: numpy array of labels, shape (N,)\n",
    "        num_val: number of validation samples\n",
    "        random_seed: random seed for reproducibility\n",
    "    Returns:\n",
    "        X_train, y_train, X_val, y_val\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    idx = np.random.permutation(X.shape[0])\n",
    "    X_shuffled = X[idx]\n",
    "    y_shuffled = y[idx]\n",
    "    X_val = X_shuffled[:num_val]\n",
    "    y_val = y_shuffled[:num_val]\n",
    "    X_train = X_shuffled[num_val:]\n",
    "    y_train = y_shuffled[num_val:]\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "# Example usage:\n",
    "# X = data['train_images']\n",
    "# y = data['train_labels']\n",
    "# X_train, y_train, X_val, y_val = split_mnist_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65260d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute classification accuracy\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the unweighted classification accuracy.\n",
    "    Args:\n",
    "        y_true: numpy array of true labels, shape (N,)\n",
    "        y_pred: numpy array of predicted labels, shape (N,)\n",
    "    Returns:\n",
    "        accuracy: float, percentage of correct predictions\n",
    "    \"\"\"\n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df196f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.1002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load MNIST data\n",
    "data = np.load('../data/mnist-data.npz')\n",
    "X = data['training_data']\n",
    "y = data['training_labels']\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, y_train, X_val, y_val = split_mnist_data(X, y, num_val=10000, random_seed=42)\n",
    "\n",
    "# Example: suppose you have a model and get predictions\n",
    "# Here we use random predictions as a placeholder\n",
    "y_val_pred = np.random.choice(np.unique(y), size=y_val.shape[0])\n",
    "\n",
    "# Compute accuracy on validation set\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the unweighted classification accuracy.\n",
    "    Args:\n",
    "        y_true: numpy array of true labels, shape (N,)\n",
    "        y_pred: numpy array of predicted labels, shape (N,)\n",
    "    Returns:\n",
    "        accuracy: float, percentage of correct predictions\n",
    "    \"\"\"\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation accuracy:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01844212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy (SVM): 0.8999\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Reshape images to (num_samples, num_features)\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val_flat = X_val.reshape(X_val.shape[0], -1)\n",
    "\n",
    "# Train SVM model\n",
    "clf = svm.SVC(kernel='linear')  # You can also try 'rbf' kernel\n",
    "clf.fit(X_train_flat[:5000], y_train[:5000])\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = clf.predict(X_val_flat)\n",
    "\n",
    "# Compute accuracy\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation accuracy (SVM):\", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8dd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.001, Validation accuracy=0.9079\n",
      "C=0.01, Validation accuracy=0.9079\n",
      "C=0.1, Validation accuracy=0.9079\n",
      "C=1, Validation accuracy=0.9079\n",
      "C=10, Validation accuracy=0.9079\n",
      "C=100, Validation accuracy=0.9079\n",
      "C=1000, Validation accuracy=0.9079\n",
      "C=10000, Validation accuracy=0.9079\n",
      "Best C: 0.001\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "accuracies = []\n",
    "\n",
    "for C in C_values:\n",
    "    clf = svm.SVC(kernel='linear', C=C)\n",
    "    clf.fit(X_train_flat[:10000], y_train[:10000])  # 至少10000个样本\n",
    "    y_val_pred = clf.predict(X_val_flat)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"C={C}, Validation accuracy={acc}\")\n",
    "    accuracies.append(acc)\n",
    "\n",
    "best_C = C_values[np.argmax(accuracies)]\n",
    "print(\"Best C:\", best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396aae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.001, 5-fold CV accuracy=0.7497008859977885\n",
      "C=0.01, 5-fold CV accuracy=0.7748738494234553\n",
      "C=0.1, 5-fold CV accuracy=0.7930938123752495\n",
      "C=1, 5-fold CV accuracy=0.8002874825887792\n",
      "C=10, 5-fold CV accuracy=0.8005275779376498\n",
      "C=100, 5-fold CV accuracy=0.8005267163514697\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "# Load spam data\n",
    "data = np.load('../data/spam-data.npz')\n",
    "X = data['training_data']\n",
    "y = data['training_labels']\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(X.shape[0])\n",
    "X_shuffled = X[indices]\n",
    "y_shuffled = y[indices]\n",
    "\n",
    "k = 5  # Number of folds\n",
    "fold_size = X.shape[0] // k\n",
    "\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "cv_accuracies = []\n",
    "\n",
    "for C in C_values:\n",
    "    fold_accuracies = []\n",
    "    for fold in range(k):\n",
    "        # Split into train and validation for this fold\n",
    "        start = fold * fold_size\n",
    "        end = (fold + 1) * fold_size if fold < k - 1 else X.shape[0]\n",
    "        X_val = X_shuffled[start:end]\n",
    "        y_val = y_shuffled[start:end]\n",
    "        X_train = np.concatenate([X_shuffled[:start], X_shuffled[end:]], axis=0)\n",
    "        y_train = np.concatenate([y_shuffled[:start], y_shuffled[end:]], axis=0)\n",
    "        \n",
    "        # Train SVM\n",
    "        clf = svm.SVC(kernel='linear', C=C)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_val)\n",
    "        acc = np.mean(y_pred == y_val)\n",
    "        fold_accuracies.append(acc)\n",
    "    avg_acc = np.mean(fold_accuracies)\n",
    "    print(f\"C={C}, 5-fold CV accuracy={avg_acc}\")\n",
    "    cv_accuracies.append(avg_acc)\n",
    "\n",
    "best_C = C_values[np.argmax(cv_accuracies)]\n",
    "print(\"Best C (5-fold CV):\", best_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2bd06c",
   "metadata": {},
   "source": [
    "k 折交叉验证（k-fold cross-validation）是一种常用的模型评估方法。其核心思想如下：\n",
    "\n",
    "- 首先将全部训练数据**随机打乱**，然后**平均分成 $k$ 份**（称为“折”）。\n",
    "- 每次选择其中一份作为**验证集**，其余 $k-1$ 份作为**训练集**，训练模型并在验证集上评估。\n",
    "- 这个过程**重复 $k$ 次**，每一份都轮流做一次验证集。\n",
    "- 最终的模型评估结果是这 $k$ 次验证的**平均准确率**。\n",
    "\n",
    "这样做的好处是：每个样本都被用作过一次验证集，评估结果更稳定，能更好地反映模型的泛化能力，尤其适合数据量较小的情况。\n",
    "\n",
    "例如，5 折交叉验证（$k=5$）就是把数据分成 5 份，分别轮流做验证集，最后取 5 次准确率的平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb8b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
